{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a21c51fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pathlib\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import db_connection\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b8399aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to database\n",
    "cursor, connection = db_connection.get_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "87032c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = str(pathlib.Path().resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "52f612e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"SELECT  e00id, e00volltext\n",
    "                    FROM e00_orgelpredigten\"\"\")\n",
    "sermons = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "47629384",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = []\n",
    "jsons = []\n",
    "for i in os.listdir(\"sermon_tables\"):\n",
    "    tables.append(i[:-4])\n",
    "for j in os.listdir(\"sermons_chunked\"):\n",
    "    jsons.append(j[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d99e94a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables unique: ['E000042', 'E000020', 'E000039', 'E000038', 'E000061', 'E000036', 'E000046', 'E000024', 'E000015', 'E000027', 'E000045', 'E000048']\n",
      "JSONs unique: []\n"
     ]
    }
   ],
   "source": [
    "tables_unique = list(set(tables) - set(jsons))\n",
    "jsons_unique = list(set(jsons) - set(tables))\n",
    "\n",
    "print(\"Tables unique:\", tables_unique)\n",
    "print(\"JSONs unique:\", jsons_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ef3644ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amend_database_entry(cursor, connection, id, amended_text):\n",
    "    sql = f\"UPDATE e00_orgelpredigten SET e00volltext = '{amended_text}' WHERE e00id = '{id}'\"\n",
    "    cursor.execute(sql)\n",
    "    connection.commit()\n",
    "    print(cursor.rowcount, \"record(s) affected\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fff88ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_whitespace_in_id(match):\n",
    "    id_value = match.group(1)\n",
    "    cleaned = ''.join(id_value.split())  # Remove all whitespace\n",
    "    return f'id=\"{cleaned}\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "530ae721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_sermon(text: str) -> str:\n",
    "      \"\"\"Cleans up organ sermon text and returns barebones xml.\n",
    "\n",
    "      The text is stripped of all editorial and layout information.\n",
    "      All tags are removed, apart from the following:\n",
    "            * musikwerk: A direkt quote from a song\n",
    "            * quelle: A quote from an authority\n",
    "            * literatur: A quote from literature\n",
    "            * bibel: A quote from the bible\n",
    "            * quote: General quoted passages\n",
    "            * orgelpredigt: A quote from another organ sermon\n",
    "      The text is returned within <xml></xml>-tags, thus hopefully\n",
    "      turning it into well-formed XML.\n",
    "\n",
    "      Args:\n",
    "          text (str): The input text\n",
    "\n",
    "      Returns:\n",
    "          str: The cleaned up text.\n",
    "      \"\"\"\n",
    "\n",
    "      rep = {\"<lb />\": \"\", \n",
    "            \"\\r\": \"\",\n",
    "            #\"\\n\": \" \",\n",
    "            \"ᵜ\": \" \",\n",
    "            \"ʬ\": \"&\",\n",
    "            \"<sic>\": \"\",\n",
    "            \"</sic>\": \"\",\n",
    "            \"<choice>\": \"\",\n",
    "            \"</choice>\": \"\",\n",
    "            \"</span>\": \"\",\n",
    "            \"<div>\": \"\",\n",
    "            \"</div>\": \"\",\n",
    "            \"<err>\": \"\",\n",
    "            \"</err>\": \"\",\n",
    "            \"<fn></fn>\": \"\",\n",
    "            \"<fn />\": \"\",\n",
    "            'typ=\"real\"': \"\",\n",
    "            '<?xml version=\"1.0\" encoding=\"UTF-8\"?>': \"\"\n",
    "            }\n",
    "\n",
    "      rep = dict((re.escape(k), v) for k, v in rep.items()) \n",
    "      pattern = re.compile(\"|\".join(rep.keys()))\n",
    "      text = pattern.sub(lambda m: rep[re.escape(m.group(0))], text)\n",
    "\n",
    "      text = re.sub(r'<pb page=\"[^\"]+\" ?\\/?>(<\\/pb>)?', \"\", text)              # remove page breaks\n",
    "      text = re.sub(r'<h[123456]>([\\S\\s]+?)<\\/h[123456]>', \"\", text)           # remove header tags\n",
    "\n",
    "      text = re.sub(r'<x?person id=\"[^\"]*\">([\\S\\s]+?(?=<))<\\/x?person>', r\"\\1\", text)              # remove persons\n",
    "      text = re.sub(r'<x?ort id=\"[^\"]*\">([\\S\\s]+?(?=<))<\\/x?ort>', r\"\\1\", text)                    # remove places\n",
    "      text = re.sub(r'<x?orgel id=\"[^\"]*\">([\\S\\s]+?(?=<))<\\/x?orgel>', r\"\\1\", text)                # remove organ\n",
    "      text = re.sub(r'<kunstwerk id=\"[^\"]*\">([\\S\\s]+?(?=<))<\\/kunstwerk>', r'\\1', text)            # remove kunstwerk\n",
    "      text = re.sub(r'<ereignis id=\"[^\"]*\">([\\S\\s]+?(?=<))<\\/ereignis>', r'\\1', text)              # remove ereignis\n",
    "\n",
    "      text = re.sub(r'<titel id=\"([^\"]*)\"( typ=\"real\")? *>([\\S\\s]+?(?=<))</titel>', r'<quelle id=\"\\1\">\\3</quelle>', text)\n",
    "\n",
    "      text = re.sub(r'<supplied>[\\S\\s]+?<\\/supplied>', \"\", text)                    # remove editorial additions\n",
    "      text = re.sub(r'<corr>[\\S\\s]+?<\\/corr>', \"\", text)                            # remove editorial corrections\n",
    "      text = re.sub(r'<ref typ=\"trl\">[\\S\\s]+?<\\/ref>', \"\", text)                    # remove translations\n",
    "      text = re.sub(r'<ref typ=\"anm\">([\\S\\s]+?(?=<\\/ref>))<\\/ref>', \"\", text)       # remove editorial comments\n",
    "      text = re.sub(r'<hi lang=\"[a-z]+\">([\\S\\s]+?)<\\/hi>', r\"\\1\", text)             # remove typographical markup\n",
    "      text = re.sub(r'(<hi rend=\"[a-z\\-]+\">)+([\\S\\s]+?)(<\\/hi>)+', r\"\\2\", text)     # remove typographical markup\n",
    "      text = re.sub(r'<\\/hi>', \"\", text)\n",
    "      text = re.sub(r'<ref typ=\"ofn\" symbol=\"\\(\\S+\\)\">', '', text)\n",
    "      text = re.sub(r'<\\/ref>', \"\", text)\n",
    "\n",
    "      text = re.sub(r'<table([\\S\\s]+?(?=<))<\\/table>', \"\", text)                          # remove tables\n",
    "\n",
    "      text = re.sub(r'<div class=\"[a-z]+\">', \"\", text)                                    # unwrap all <div> tags\n",
    "      text = re.sub(r'=\\s+', \"\", text)                                                    # undo hyphenations\n",
    "      text = re.sub(r'<note>[\\S\\s]+?<\\/note>', \"\", text)                                  # remove marginal notes\n",
    "      text = re.sub(r'<span[^>]+>', \"\", text)\n",
    "\n",
    "      text = re.sub(r'[\\s\\n]+', ' ', text)                                                # collapse all whitespace\n",
    "      text = re.sub(r'([\"\\'\\(\\)»«›‹\\.,\\;])<', r'\\1 <',text)\n",
    "      text = re.sub(r'>([\"\\'\\(\\)»«›‹\\.,\\;])', '> \\1', text)\n",
    "      text = re.sub(r'id=\"([^\"]+)\"', remove_whitespace_in_id, text)                       # remove whitespace in IDs\n",
    "      text = re.sub(r' </', '</', text)                                                   # remove whitespace before closing tags\n",
    "      text = re.sub(r'\\x01', '', text)\n",
    "\n",
    "      #text = re.sub(r'[/\\.,;=\\?!|]', '', text)\n",
    "      \n",
    "      return \"<xml> \" + text + \" </xml>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9397b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_quotes(soup):\n",
    "    # find all quote tags that are inside other tags or contain other tags and remove them\n",
    "    for quote in soup.find_all(\"quote\"):\n",
    "        # If <quote> has children tags or is nested inside another tag (not direct child of root)\n",
    "        has_nested_tags = any(child.name for child in quote.children)\n",
    "        is_nested_in_another_tag = quote.parent.name != \"root\"\n",
    "\n",
    "        if has_nested_tags or is_nested_in_another_tag:\n",
    "            quote.unwrap()\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2fa4f0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(word):\n",
    "    return re.sub(r'[=*\\(\\)\\[\\]]', '', word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c32c8088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:93: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:93: SyntaxWarning: invalid escape sequence '\\S'\n",
      "/tmp/ipykernel_14071/2401908148.py:93: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  refs = re.findall('\"(\\S*?)\"', word)\n"
     ]
    }
   ],
   "source": [
    "def soup_to_table(text: str) -> list:\n",
    "    \"\"\"Takes an xml string and turns it into a table of words and attributes\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to be searched\n",
    "    \n",
    "    Returns:\n",
    "        list: A table with the columns 'word', 'types', and 'reference'\n",
    "    \"\"\"\n",
    "\n",
    "    return_table = []\n",
    "    \n",
    "    status = {\n",
    "        \"bibel\": False,\n",
    "        \"quote\": False,\n",
    "        \"quelle\": False,\n",
    "        \"musikwerk\": False,\n",
    "        \"literatur\": False,\n",
    "        \"orgelpredigt\": False\n",
    "        }\n",
    "\n",
    "    reference = []\n",
    "    typemarker = \"\"\n",
    "\n",
    "    openingtag = re.compile('<[^/]')\n",
    "    irrelevantid = re.compile('id=\"E0[1234567][0-9]+\"')\n",
    "\n",
    "    words = re.split(r'[> ]+', text)\n",
    "\n",
    "    for word in words:\n",
    "        # update type assignment\n",
    "        typemarker = \"\"\n",
    "        for k, i in status.items():\n",
    "            if i:\n",
    "                typemarker = \" \".join([typemarker, k])\n",
    "\n",
    "        if re.match(openingtag, word):\n",
    "            if word.startswith((\"<xml\", \"</xml\")):\n",
    "                continue\n",
    "            elif word.startswith(\"<bibel\"):\n",
    "                status[\"bibel\"] = True\n",
    "                continue\n",
    "            elif word.startswith(\"<quote\"):\n",
    "                status[\"quote\"] = True\n",
    "                continue\n",
    "            elif word.startswith(\"<quelle\"):\n",
    "                status[\"quelle\"] = True\n",
    "                continue\n",
    "            elif word.startswith(\"<musikwerk\"):\n",
    "                status[\"musikwerk\"] = True\n",
    "                continue\n",
    "            elif word.startswith(\"<literatur\"):\n",
    "                status[\"literatur\"] = True\n",
    "                continue\n",
    "            elif word.startswith(\"<predigt\"):\n",
    "                status[\"orgelpredigt\"] = True\n",
    "                continue\n",
    "            else:                               # ignore other stray tag fragments\n",
    "                continue\n",
    "\n",
    "        elif \"</\" in word:\n",
    "            if word.endswith(\"</bibel\"):\n",
    "                status[\"bibel\"] = False\n",
    "                row = (word[:-7], typemarker, reference)\n",
    "                reference = reference[:-1]\n",
    "            elif word.endswith(\"</quote\"):\n",
    "                status[\"quote\"] = False\n",
    "                row = (word[:-7], typemarker, reference)\n",
    "                reference = reference[:-1]\n",
    "            elif word.endswith(\"</quelle\"):\n",
    "                status[\"quelle\"] = False\n",
    "                row = (word[:-8], typemarker, reference)\n",
    "                reference = reference[:-1]\n",
    "            elif word.endswith(\"</musikwerk\"):\n",
    "                status[\"musikwerk\"] = False\n",
    "                row = (word[:-11], typemarker, reference)\n",
    "                reference = reference[:-1]\n",
    "            elif word.endswith(\"</literatur\"):\n",
    "                status[\"literatur\"] = False\n",
    "                row = (word[:-11], typemarker, reference)\n",
    "                reference = reference[:-1]\n",
    "            elif word.endswith(\"</predigt\"):\n",
    "                status[\"orgelpredigt\"] = False\n",
    "                row = (word[:-9], typemarker, reference)\n",
    "                reference = reference[:-1]\n",
    "            else:\n",
    "                row = (word.split(\"</\")[0], typemarker, reference)\n",
    "        \n",
    "        elif word.startswith(\"id=\"):\n",
    "            if re.match(irrelevantid, word):\n",
    "                continue\n",
    "            else:\n",
    "                refs = re.findall('\"(\\S*?)\"', word)\n",
    "                if refs:\n",
    "                    reference = reference + refs\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            row = (word, typemarker, reference)\n",
    "        return_table.append(row)\n",
    "\n",
    "    return return_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d058cb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('E000042', '')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sermons[41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d543871b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting. Nr: 0, ID: E000001\n",
      "Saved E000001\n",
      "Starting. Nr: 1, ID: E000002\n",
      "Saved E000002\n",
      "Starting. Nr: 2, ID: E000003\n",
      "Saved E000003\n",
      "Starting. Nr: 3, ID: E000004\n",
      "Starting. Nr: 4, ID: E000005\n",
      "Starting. Nr: 5, ID: E000006\n",
      "Starting. Nr: 6, ID: E000007\n",
      "Saved E000007\n",
      "Starting. Nr: 7, ID: E000008\n",
      "Saved E000008\n",
      "Starting. Nr: 8, ID: E000009\n",
      "Saved E000009\n",
      "Starting. Nr: 9, ID: E000010\n",
      "Starting. Nr: 10, ID: E000011\n",
      "Starting. Nr: 11, ID: E000012\n",
      "Starting. Nr: 12, ID: E000013\n",
      "Starting. Nr: 13, ID: E000014\n",
      "Saved E000014\n",
      "Starting. Nr: 14, ID: E000015\n",
      "Saved E000015\n",
      "Starting. Nr: 15, ID: E000016\n",
      "Saved E000016\n",
      "Starting. Nr: 16, ID: E000017\n",
      "Starting. Nr: 18, ID: E000019\n",
      "Starting. Nr: 19, ID: E000020\n",
      "Saved E000020\n",
      "Starting. Nr: 20, ID: E000021\n",
      "Saved E000021\n",
      "Starting. Nr: 21, ID: E000022\n",
      "Starting. Nr: 22, ID: E000023\n",
      "Saved E000023\n",
      "Starting. Nr: 23, ID: E000024\n",
      "Saved E000024\n",
      "Starting. Nr: 24, ID: E000025\n",
      "Starting. Nr: 25, ID: E000026\n",
      "Starting. Nr: 26, ID: E000027\n",
      "Saved E000027\n",
      "Starting. Nr: 27, ID: E000028\n",
      "Starting. Nr: 28, ID: E000029\n",
      "Saved E000029\n",
      "Starting. Nr: 29, ID: E000030\n",
      "Saved E000030\n",
      "Starting. Nr: 31, ID: E000032\n",
      "Starting. Nr: 32, ID: E000033\n",
      "Starting. Nr: 33, ID: E000034\n",
      "Saved E000034\n",
      "Starting. Nr: 34, ID: E000035\n",
      "Saved E000035\n",
      "Starting. Nr: 35, ID: E000036\n",
      "Saved E000036\n",
      "Starting. Nr: 36, ID: E000037\n",
      "Saved E000037\n",
      "Starting. Nr: 37, ID: E000038\n",
      "Saved E000038\n",
      "Starting. Nr: 38, ID: E000039\n",
      "Saved E000039\n",
      "Starting. Nr: 39, ID: E000040\n",
      "Starting. Nr: 40, ID: E000041\n",
      "Saved E000041\n",
      "Starting. Nr: 41, ID: E000042\n",
      "Saved E000042\n",
      "Starting. Nr: 42, ID: E000043\n",
      "Starting. Nr: 43, ID: E000044\n",
      "Starting. Nr: 44, ID: E000045\n",
      "Saved E000045\n",
      "Starting. Nr: 45, ID: E000046\n",
      "Saved E000046\n",
      "Starting. Nr: 46, ID: E000047\n",
      "Starting. Nr: 47, ID: E000048\n",
      "Saved E000048\n",
      "Starting. Nr: 48, ID: E000049\n",
      "Starting. Nr: 49, ID: E000050\n",
      "Starting. Nr: 50, ID: E000051\n",
      "Saved E000051\n",
      "Starting. Nr: 51, ID: E000052\n",
      "Saved E000052\n",
      "Starting. Nr: 52, ID: E000053\n",
      "Saved E000053\n",
      "Starting. Nr: 53, ID: E000054\n",
      "Starting. Nr: 54, ID: E000055\n",
      "Saved E000055\n",
      "Starting. Nr: 55, ID: E000056\n",
      "Saved E000056\n",
      "Starting. Nr: 56, ID: E000057\n",
      "Saved E000057\n",
      "Starting. Nr: 57, ID: E000058\n",
      "Saved E000058\n",
      "Starting. Nr: 58, ID: E000059\n",
      "Saved E000059\n",
      "Starting. Nr: 59, ID: E000060\n",
      "Saved E000060\n",
      "Starting. Nr: 60, ID: E000061\n",
      "Saved E000061\n",
      "Starting. Nr: 61, ID: E000062\n",
      "Starting. Nr: 62, ID: E000063\n",
      "Saved E000063\n",
      "Starting. Nr: 63, ID: E000065\n",
      "Saved E000065\n",
      "Starting. Nr: 64, ID: E000066\n",
      "Starting. Nr: 65, ID: E000067\n",
      "Saved E000067\n",
      "Starting. Nr: 66, ID: E000068\n",
      "Saved E000068\n",
      "Starting. Nr: 67, ID: E000069\n",
      "Saved E000069\n",
      "Starting. Nr: 68, ID: E000070\n",
      "Saved E000070\n",
      "Starting. Nr: 69, ID: E000071\n",
      "Starting. Nr: 70, ID: E000072\n",
      "Saved E000072\n",
      "Starting. Nr: 71, ID: E000073\n",
      "Saved E000073\n",
      "Starting. Nr: 72, ID: E000074\n",
      "Saved E000074\n",
      "Starting. Nr: 73, ID: E000075\n",
      "Saved E000075\n",
      "Starting. Nr: 74, ID: E000076\n",
      "Starting. Nr: 75, ID: E000077\n",
      "Starting. Nr: 76, ID: E000078\n",
      "Saved E000078\n",
      "Starting. Nr: 77, ID: E000079\n",
      "Saved E000079\n",
      "Starting. Nr: 78, ID: E000080\n",
      "Starting. Nr: 79, ID: E000081\n",
      "Starting. Nr: 80, ID: E000082\n",
      "Saved E000082\n",
      "Starting. Nr: 81, ID: E000083\n",
      "Saved E000083\n",
      "Starting. Nr: 82, ID: E000084\n",
      "Starting. Nr: 83, ID: E000085\n",
      "Saved E000085\n",
      "Starting. Nr: 84, ID: E000086\n",
      "Saved E000086\n",
      "Starting. Nr: 85, ID: E000087\n",
      "Starting. Nr: 86, ID: E000088\n",
      "Starting. Nr: 87, ID: E000089\n",
      "Saved E000089\n",
      "Starting. Nr: 88, ID: E000090\n",
      "Saved E000090\n",
      "Starting. Nr: 89, ID: E000091\n",
      "Saved E000091\n",
      "Starting. Nr: 90, ID: E000092\n",
      "Saved E000092\n",
      "Starting. Nr: 91, ID: E000093\n",
      "Starting. Nr: 92, ID: E000094\n",
      "Starting. Nr: 93, ID: E000095\n",
      "Saved E000095\n",
      "Starting. Nr: 94, ID: E000096\n",
      "Saved E000096\n",
      "Starting. Nr: 95, ID: E000097\n",
      "Starting. Nr: 96, ID: E000098\n",
      "Saved E000098\n",
      "Starting. Nr: 97, ID: E000099\n",
      "Saved E000099\n",
      "Starting. Nr: 98, ID: E000100\n",
      "Starting. Nr: 99, ID: E000101\n",
      "Starting. Nr: 100, ID: E000102\n",
      "Starting. Nr: 101, ID: E000103\n",
      "Starting. Nr: 102, ID: E000104\n",
      "Saved E000104\n",
      "Starting. Nr: 103, ID: E000105\n",
      "Starting. Nr: 104, ID: E000106\n",
      "Saved E000106\n",
      "Starting. Nr: 105, ID: E000107\n",
      "Starting. Nr: 106, ID: E000108\n",
      "Saved E000108\n",
      "Starting. Nr: 107, ID: E000109\n",
      "Saved E000109\n"
     ]
    }
   ],
   "source": [
    "inbetween_text = \"\"\n",
    "for k, i in  enumerate(sermons):                    # iterate over sermons to create tables\n",
    "    predigtid = i[0]\n",
    "    predigttext = i[1]\n",
    "    if predigtid not in [\"E000031\", \"E000018\"]:                      # note: E000031 should be excepted since theres no markup!\n",
    "        print(f\"Starting. Nr: {k}, ID: {predigtid}\")\n",
    "\n",
    "        predigttext_cleaned = cleanup_sermon(predigttext)       # clean up raw markup\n",
    "        soup = BeautifulSoup(predigttext_cleaned, 'html.parser')\n",
    "        if len(soup.text) > 500:\n",
    "            paras = []\n",
    "            for par in soup.find_all(\"p\"):\n",
    "                if par.find(\"p\"):\n",
    "                    continue\n",
    "                else:\n",
    "                    \n",
    "                    soup = remove_quotes(par)\n",
    "                    text = soup_to_table(re.sub(r\"\\x01\", \"\", str(soup)))    # turn markup into table\n",
    "                                        # create df for long enough sermons\n",
    "                    df = pd.DataFrame(text, columns=[\"word\", \"types\", \"reference\"])\n",
    "                    df['word'] = df['word'].apply(remove_punctuation)   # remove remaining punct.\n",
    "                    df['word'] = df['word'].str.lower()                 # lowercase\n",
    "                    df = df[df['word'].astype(bool)]                    # remove empty rows\n",
    "                    words = df[\"word\"].values.tolist()\n",
    "                    types = df[\"types\"].values.tolist()\n",
    "                    references = df[\"reference\"].values.tolist()\n",
    "\n",
    "                    paras.append([words, types, references])\n",
    "\n",
    "            delimiters = [\"/\", \".\", \",\", \":\", \"!\", \"?\", \";\"]\n",
    "\n",
    "            all_paras = []\n",
    "\n",
    "            for para in paras:\n",
    "                if para[0] == []:\n",
    "                    continue\n",
    "\n",
    "                all_sents = []\n",
    "\n",
    "                words = para[0]\n",
    "                types = para[1]\n",
    "                refs = para[2]\n",
    "\n",
    "                inbetween_text += \" \".join(words)\n",
    "\n",
    "                sent_words = []\n",
    "                sent_types = []\n",
    "                sent_refs = []\n",
    "\n",
    "                for i in range(len(words)):\n",
    "                    if i == len(words) - 1:\n",
    "                        sent_words.append(words[i])\n",
    "                        sent_types.append(types[i])\n",
    "                        sent_refs.append(refs[i])\n",
    "\n",
    "                        all_sents.append([sent_words, sent_types, sent_refs])\n",
    "                    else:\n",
    "                        if any(x in words[i] for x in delimiters):\n",
    "                            sent_words.append(words[i])\n",
    "                            sent_types.append(types[i])\n",
    "                            sent_refs.append(refs[i])\n",
    "                            \n",
    "                            if len(sent_words) >= 4:\n",
    "                                all_sents.append([sent_words, sent_types, sent_refs])\n",
    "                                \n",
    "                                sent_words = []\n",
    "                                sent_types = []\n",
    "                                sent_refs = []\n",
    "                        else:\n",
    "                            sent_words.append(words[i])\n",
    "                            sent_types.append(types[i])\n",
    "                            sent_refs.append(refs[i])\n",
    "                \n",
    "                all_paras.append(all_sents)\n",
    "\n",
    "            sermon_dict = []\n",
    "\n",
    "            all_paragraphs = []\n",
    "\n",
    "            for para in all_paras:\n",
    "                all_sents = []\n",
    "                \n",
    "                for sent in para:\n",
    "\n",
    "                    words = sent[0]\n",
    "                    types = sent[1]\n",
    "                    refs = sent[2]\n",
    "                    sentence = {}\n",
    "                    sentence[\"words\"] = words\n",
    "                    sentence[\"types\"] = types\n",
    "                    sentence[\"references\"] = refs\n",
    "\n",
    "                    all_sents.append(sentence)\n",
    "                all_paragraphs.append(all_sents)\n",
    "            \n",
    "            with open(f\"sermons_chunked/{predigtid}.json\", \"w\") as f:\n",
    "                json.dump(all_paragraphs, f, ensure_ascii=False)\n",
    "            print(f\"Saved {predigtid}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma_orgelpredigt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
